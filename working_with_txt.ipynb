{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## AE1 - Working With Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97dce5eb2b4a7e12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Library Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e67d554c568e33b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T12:16:45.659713Z",
     "start_time": "2024-03-03T12:16:43.212670Z"
    }
   },
   "id": "c31d04d3ba50ac63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Download Stopwords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2043b9c76a193bf"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/owensharpe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/owensharpe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/owensharpe/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/owensharpe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# remove apostrophes\n",
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words = [word.replace(\"'\", \"\") for word in stop_words]\n",
    "\n",
    "# adding my own stop-words\n",
    "my_stop_words = ['im', 'like', 'get', 'got', 'aint',\n",
    "                    'dont', 'oh', 'yeah', 'cause', 'verse',\n",
    "                    'chorus', 'know', 'na', 'right', 'thats',\n",
    "                    'cant', 'never', 'see', 'say', 'back', 'go',\n",
    "                    'tell', 'make', 'need', 'take', 'let', 'youre',\n",
    "                    'want', 'ya', 'hook', 'wrong', 'look', 'come',\n",
    "                    'thought', 'wan', 'way', 'ill', 'keep', 'feel',\n",
    "                    'could', 'even', 'gon', 'em', 'still', 'think',\n",
    "                    'every']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T12:16:46.653596Z",
     "start_time": "2024-03-03T12:16:46.501767Z"
    }
   },
   "id": "134a6ca93acb7671"
  },
  {
   "cell_type": "markdown",
   "source": [
    "DISClAIMER: I made all of these functions and additions in order of the prompt, and then created a 'main' where the user can input two artists and then see the desired outputs for each artist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a06bcba9a646a409"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Loading and Pre-Processing Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32b9dfa60311e25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    :param text: a specific song text\n",
    "    :return: a list of the song's words\n",
    "    \"\"\"\n",
    "    \n",
    "    # turn to lowercase\n",
    "    cleaned_text = text.strip().lower()\n",
    "    \n",
    "    # remove special characters, digits, and redundant whitespace\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)  \n",
    "    cleaned_text = re.sub(r'\\d', '', cleaned_text) \n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        \n",
    "    return cleaned_text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8ae4e2beee403a9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_cleaned_words(text):\n",
    "    \"\"\"\n",
    "    :param text: a group of a text from a cell of a dataframe\n",
    "    :return: cleaned words that are declared as meaningful\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the words from the cleaned text\n",
    "    cleaned_text = clean_text(text)\n",
    "    words = word_tokenize(cleaned_text)\n",
    "\n",
    "    # what are considered 'meaningless' words? anyway, remove them\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words and word not in my_stop_words:\n",
    "            cleaned_words.append(word)\n",
    "    \n",
    "    return cleaned_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T12:16:54.832535Z",
     "start_time": "2024-03-03T12:16:54.811752Z"
    }
   },
   "id": "f697dc685b1a7ed9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read data\n",
    "spotify_df = pd.read_csv(\"spotify_millsongdata.csv\")\n",
    "\n",
    "# make a new cleaned text column and clean text for each row/song\n",
    "spotify_df['cleaned_words'] = spotify_df['text'].apply(get_cleaned_words)\n",
    "\n",
    "# get rid of link column, as not really needed\n",
    "del spotify_df['link']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9b9ffd056cc1c46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Analysing Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2429d9c1cc2eadd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### i) Get Word Frequencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeca21c324f91443"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_word_frequencies(artist_dict, word_list):\n",
    "    \"\"\"\n",
    "    :param artist_dict: a dictionary of an artists word frequency\n",
    "    :param word_list: a list of words from a specific song\n",
    "    :return: updated artist dictionary having added song\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in artist_dict:\n",
    "            artist_dict[word] += 1\n",
    "        else:\n",
    "            artist_dict[word] = 1\n",
    "    \n",
    "    return artist_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667813a02a668ddf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the word frequencies of each artist\n",
    "artist_words = []\n",
    "\n",
    "# gather all unique artists from the dataframe\n",
    "artists = spotify_df['artist'].unique()\n",
    "\n",
    "for artist in artists:\n",
    "    temp_list = [artist]\n",
    "    temp_word_freq = {}\n",
    "    \n",
    "    # get the specific rows of the artist from the dataframe \n",
    "    artist_df = spotify_df.loc[spotify_df['artist'] == artist]\n",
    "    \n",
    "    # get the word frequencies for all the songs related to the artist\n",
    "    for index, row in artist_df.iterrows():\n",
    "        temp_word_freq = get_word_frequencies(temp_word_freq, row['cleaned_words'])\n",
    "    \n",
    "    # add the frequencies to the temp_list, and then add the temp_list to the artist list\n",
    "    temp_list.append(temp_word_freq)\n",
    "    artist_words.append(temp_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc38e67f35d9f6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ii) Determining the Word Richness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "746b5b0cbe8807bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_word_richness(all_artist_info):\n",
    "    \"\"\"\n",
    "    :param all_artist_info: each artist's information and unique word count\n",
    "    :return: artists with their richness score between 0 and 10\n",
    "    \"\"\"\n",
    "    \n",
    "    # sort the artists based upon the amount of unique words \n",
    "    sorted_artists = sorted(all_artist_info, key = lambda x: x[2], reverse=True)    \n",
    "    \n",
    "    # create a rank for the artist\n",
    "    ranks = {sorted_artist[0]: i+1 for i, sorted_artist in enumerate(sorted_artists)}\n",
    "    \n",
    "    # getting the top rank\n",
    "    max_rank = len(sorted_artists)\n",
    "    \n",
    "    # calculate the score \n",
    "    for spec_artist in all_artist_info:\n",
    "        \n",
    "        temp_rank = ranks[spec_artist[0]]\n",
    "        \n",
    "        # get a score between 0-10\n",
    "        temp_score = (max_rank - temp_rank) / max_rank * 10\n",
    "        spec_artist.append(temp_score)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76039edb1e00c256"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get unique word counts for each artist\n",
    "for artist in artist_words:\n",
    "    \n",
    "    # get the count and append information to the artist\n",
    "    unique_word_count = len(artist[1])\n",
    "    artist.append(unique_word_count)\n",
    "\n",
    "# creating a richness score from 0-10; I will rank each artist on unique words then formulate a score\n",
    "calc_word_richness(artist_words)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af5b906ec32a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### iii) Getting the Sentiment Score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71612db92e8f58e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sentiment(word_list):\n",
    "    \"\"\"\n",
    "    :param word_list: a list of words from a specific song\n",
    "    :return: the sentiment score of a specific song\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # get the score using the words\n",
    "    total_sent_score = 0\n",
    "    for word in word_list:\n",
    "        sentiment = sia.polarity_scores(word)\n",
    "            \n",
    "        # aggregate the sentiment scores\n",
    "        total_sent_score += sentiment['compound']\n",
    "        \n",
    "    # get the average score and append to the artist's information\n",
    "    avg_sent_score = total_sent_score / len(word_list)\n",
    "    \n",
    "    return avg_sent_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c89733a85d16623"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the sentiment scores for the songs, ranging from -1 to 1\n",
    "spotify_df['sentiment_score'] = spotify_df['cleaned_words'].apply(get_sentiment)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200a4b000fa928b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### iv) Identifying any Common Words between Artists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53f1d41b56ac1f7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this, I am getting the top 25 most common words between artists, but you could pick any number 'n' to be used"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c709458b3a32f8f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_common_words(both_artist_info, top_n=25):\n",
    "    \"\"\"\n",
    "    :param both_artist_info: each artist's information\n",
    "    :param top_n: the top n number of common words between artists\n",
    "    :return: the top n number most common words between all artists\n",
    "    \"\"\"\n",
    "    \n",
    "    # find common words\n",
    "    com_words = set(both_artist_info[0][1].keys()) & set(both_artist_info[1][1].keys())\n",
    "\n",
    "    # count occurrences of common words across both artists\n",
    "    common_word_counts = {word: both_artist_info[0][1][word] + both_artist_info[1][1][word]\n",
    "                          for word in com_words}\n",
    "    \n",
    "    # sort common words by frequency\n",
    "    top_n_common_words = sorted(common_word_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return top_n_common_words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c110f169bd40ab5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Visualizing Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e22b69f59192c5d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### i) Generating a Word Cloud for each Artist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9893905d8b8249a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_word_cloud(artist_info):\n",
    "    \"\"\"\n",
    "    :param artist_info: an artist's specific information\n",
    "    :return: null (plotting)\n",
    "    \"\"\"\n",
    "        \n",
    "    # generate word cloud\n",
    "    artist_wordcloud = WordCloud(width=800, height=400,\n",
    "                                 background_color='white').generate_from_frequencies(artist_info[1])\n",
    "        \n",
    "    # plot specific artist wordcloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(artist_wordcloud, interpolation='bilinear')\n",
    "    plt.title(artist_info[0] + \"'s Word Cloud\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48ea6a9dc556131"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ii) Plotting Sentiment Scores in a Scatter Plot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14325a7b27ec09fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sentiment(dataframe, artist_name):\n",
    "    \"\"\"\n",
    "    :param dataframe: specific spotify song information\n",
    "    :param artist_name: the artist's name\n",
    "    :return: null (plotting)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a filtered dataframe\n",
    "    spec_artist_df = dataframe.loc[spotify_df['artist'] == artist_name]\n",
    "    \n",
    "    # make scatter plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    count = 0\n",
    "    for _, curr_row in spec_artist_df.iterrows():\n",
    "        plt.scatter(count, curr_row['sentiment_score'])\n",
    "        plt.text(count, curr_row['sentiment_score'], curr_row['song'], fontsize=5, ha='right')\n",
    "        count += 1\n",
    "    \n",
    "    # give plot additions\n",
    "    plt.title(f\"{artist_name}'s Song Sentiment Scores\")\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acac8aea155953f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### iii) Creating a Heat Map to Show Word Overlap Between Artists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "644786092b85dd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_top_words(word_dict, top_n=25):\n",
    "    \"\"\"\n",
    "    :param word_dict: an artist's word frequency dictionary\n",
    "    :param top_n: the top n number of common words for an artist\n",
    "    :return: the most common words\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_word_freq = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # take the top n words\n",
    "    top_n_words = sorted_word_freq[:top_n]\n",
    "    \n",
    "    return top_n_words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62bd530679641ea1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_heatmap(both_artist_info):\n",
    "    \"\"\"\n",
    "    :param both_artist_info: each artist's specific information\n",
    "    :return: null (plotting)\n",
    "    \"\"\"\n",
    "    \n",
    "    # get each artists top n common words and frequencies\n",
    "    art1_top_words, art1_word_frequencies = map(list, zip(*get_top_words(both_artist_info[0][1])))\n",
    "    art2_top_words, art2_word_frequencies = map(list, zip(*get_top_words(both_artist_info[1][1])))\n",
    "    \n",
    "    # find all words\n",
    "    all_words = art1_top_words + art2_top_words\n",
    "\n",
    "    # initialize frequency matrices\n",
    "    art1_freq_matrix = []\n",
    "    art2_freq_matrix = []\n",
    "    \n",
    "    # iterate over all words\n",
    "    for word in all_words:\n",
    "        if word in art1_top_words:\n",
    "            art1_freq_matrix.append(art1_word_frequencies[art1_top_words.index(word)])\n",
    "        else:\n",
    "            art1_freq_matrix.append(0)  \n",
    "        \n",
    "        if word in art2_top_words:\n",
    "            art2_freq_matrix.append(art2_word_frequencies[art2_top_words.index(word)])\n",
    "        else:\n",
    "            art2_freq_matrix.append(0) \n",
    "    \n",
    "    # convert to numpy arrays and reshape\n",
    "    art1_np_matrix = (np.array(art1_freq_matrix)).reshape(1, -1)\n",
    "    art2_np_matrix = (np.array(art2_freq_matrix)).reshape(1, -1)\n",
    "    \n",
    "    # stack matrices vertically (this helped my visualization)\n",
    "    heatmap_data = np.vstack((art1_np_matrix, art2_np_matrix))\n",
    "    heatmap_data_transposed = heatmap_data.T\n",
    "\n",
    "    # get artist names\n",
    "    artist_names = [spec_artist[0] for spec_artist in both_artist_info]\n",
    "\n",
    "    # plot heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(heatmap_data_transposed, cmap='viridis', aspect='auto')\n",
    "    \n",
    "    # additional plot adjustments\n",
    "    plt.colorbar(label='Frequency')\n",
    "    plt.yticks(range(len(all_words)), all_words, fontsize=8, rotation=0)\n",
    "    plt.xticks(range(2), [artist_names[0], artist_names[1]])\n",
    "    plt.title('Common Words Heatmap for Both Artists')\n",
    "    \n",
    "    # show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b6942c9c7ac286c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4) Generating Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ee99251819d48b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_artists():\n",
    "    \"\"\"\n",
    "    :return: specified artist1 and artist2\n",
    "    \"\"\"\n",
    "    \n",
    "    # prompt user for the artists\n",
    "    art1 = (input(\"Who is the first artist you want?: \"))\n",
    "    art2 = (input(\"Who is the second artist you want?: \"))\n",
    "    \n",
    "    return art1, art2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af6332dfde0a16bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_song_texts(spec_artist, dataframe):\n",
    "    \"\"\"\n",
    "    :param spec_artist: a specified artist\n",
    "    :param dataframe: specific spotify song information\n",
    "    :return: all the cleaned song lyrics of the artist\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a filtered df for the artist\n",
    "    spec_artist_df = dataframe[dataframe['artist'] == spec_artist]\n",
    "    \n",
    "    # initialize a list for the artist's lyrics and append all song lyrics to that list\n",
    "    all_lyrics = \"\"\n",
    "    \n",
    "    # call the clean_text function from earlier to get all the natural words from the text\n",
    "    for _, curr_row in spec_artist_df.iterrows():\n",
    "        temp_cleaned_text = clean_text(curr_row['text'])\n",
    "        all_lyrics += (\" \" + temp_cleaned_text)\n",
    "    \n",
    "    return all_lyrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa9344f4e042e39c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    :param text: text containing all song lyrics from the artist \n",
    "    :param n: number for n-grams (i.e. two-grams, three-grams, four-grams)\n",
    "    :return: the n-grams\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize ngrams and split the text for the words\n",
    "    ngrams = defaultdict(list)\n",
    "    words = text.split()\n",
    "    \n",
    "    # loop through words and create n-grams\n",
    "    for i in range(len(words) - n):\n",
    "        ngrams[tuple(words[i:i+n])].append(words[i+n])\n",
    "        \n",
    "    return ngrams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc42ffe1798197a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_song(ngrams, n_words=150):\n",
    "    \"\"\"\n",
    "    :param ngrams: n-grams created for an artist\n",
    "    :param n_words: number of words for the song\n",
    "    :return: the generated song text\n",
    "    \"\"\"\n",
    "    \n",
    "    # get a random starter word using the ngram keys\n",
    "    starter_word = random.choice(list(ngrams.keys()))\n",
    "    \n",
    "    # initialize text\n",
    "    generated_song = list(starter_word)\n",
    "    \n",
    "    # loop until number of words is hit, adding words through the n-grams along the way\n",
    "    for _ in range(n_words):\n",
    "        \n",
    "        # this line gives us a window of n words from the end of the generated song\n",
    "        # it's used as the starter word for the next word prediction\n",
    "        next_word = random.choice(ngrams[tuple(generated_song[-len(starter_word):])])\n",
    "        generated_song.append(next_word)\n",
    "    \n",
    "    return ' '.join(generated_song)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c345a180cb74c453"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### User Prompting/Getting Visualizations and Outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac688f2a56132b16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_spec_artist_info(artist_info, artist_name):\n",
    "    \"\"\"\n",
    "    :param artist_info: each artist's specific information\n",
    "    :param artist_name: the name of a specific artist\n",
    "    :return: the information for that specific artist\n",
    "    \"\"\"\n",
    "    \n",
    "    for spec_artist in artist_info:\n",
    "        if artist_name in spec_artist:\n",
    "            return spec_artist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fcacf2792e7b7d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prompt user for n_grams\n",
    "n_gms = int(input(\"What is the number of n-grams you want for lyric generation?: \"))\n",
    "\n",
    "# get artists\n",
    "artist1, artist2 = get_artists()\n",
    "\n",
    "# check if artists exist in the available artists\n",
    "while artist1 not in spotify_df['artist'].values or artist2 not in spotify_df['artist'].values:\n",
    "        \n",
    "    if artist1 not in spotify_df['artist'].values:\n",
    "        print(f\"{artist1} is not in the available list!\")\n",
    "    elif artist2 not in spotify_df['artist'].values:\n",
    "        print(f\"{artist2} is not in the available list!\")\n",
    "        \n",
    "    artist1, artist2 = get_artists()\n",
    "\n",
    "# get the main information for each artist\n",
    "artist1_info = get_spec_artist_info(artist_words, artist1)\n",
    "artist2_info = get_spec_artist_info(artist_words, artist2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8006168825bd5bb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to print the word frequencies for each artist\n",
    "art1_sorted_dict = dict(sorted(artist1_info[1].items(), key=lambda item: item[1], reverse=True))\n",
    "art2_sorted_dict =  dict(sorted(artist2_info[1].items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print(f\"{artist1_info[0]}'s Word Frequencies: \\n\\n {art1_sorted_dict} \\n\\n\")\n",
    "print(f\"{artist2_info[0]}'s Word Frequencies: \\n\\n {art2_sorted_dict}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5608c1765af6214f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to print the amount of unique words and the word richness scores of each artist\n",
    "print(f\"{artist1_info[0]}'s Number of Unique Words: {artist1_info[2]}\\n\"\n",
    "      f\"{artist1_info[0]}'s Word Richness Score: {artist1_info[3]}\\n\\n\")\n",
    "print(f\"{artist2_info[0]}'s Number of Unique Words: {artist2_info[2]}\\n\"\n",
    "      f\"{artist2_info[0]}'s Word Richness Score: {artist2_info[3]}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4852b8c04b4c92b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to print the top 25 words between artist 1 and artist 2\n",
    "both_artist_information = [artist1_info, artist2_info]\n",
    "common_words = find_common_words(both_artist_information)\n",
    "print(f\"The top 25 most common words between {artist1_info[0]} and {artist2_info[0]}: {common_words}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ef6f2f497db1cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to generate a wordcloud for each artist\n",
    "generate_word_cloud(artist1_info)\n",
    "generate_word_cloud(artist2_info)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f73afae6fe421d20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to make song sentiment score graphs for each artist\n",
    "plot_sentiment(spotify_df, artist1_info[0])\n",
    "plot_sentiment(spotify_df, artist2_info[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "569d84cbeddccfbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to make heat maps to see the common word overlap between two artists\n",
    "create_heatmap(both_artist_information)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "316b1424430349f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run to create two generated songs for each artist\n",
    "\n",
    "# get all song lyrics from both artists\n",
    "artist_lyrics_1 = get_all_song_texts(artist1, spotify_df)\n",
    "artist_lyrics_2 = get_all_song_texts(artist2, spotify_df)\n",
    "\n",
    "# train n-grams for each artist\n",
    "artist1_ngrams = create_ngrams(artist_lyrics_1, n_gms)\n",
    "artist2_ngrams = create_ngrams(artist_lyrics_2, n_gms)\n",
    "\n",
    "# generate a new song for each artist\n",
    "new_song_artist1 = generate_song(artist1_ngrams)\n",
    "new_song_artist2 = generate_song(artist2_ngrams)\n",
    "\n",
    "print(f\"{artist1} generated song: \\n\\n {new_song_artist1}\\n\")\n",
    "print(f\"{artist2} generated song: \\n\\n {new_song_artist2}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42723e9f9f24e28b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5) Reflecting on the process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3372f4308434adf2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I enjoyed most of the elements of this assignment, especially the creation of some unique functions. I would say everything up to the text generation was pretty straightforward. The only thing that I could really change was determining word richness because things like cleaning text, getting word frequencies, and getting sentiment scores are usually done in a specific way that everyone follows. \n",
    "\n",
    "I liked making a personal word richness score because it allowed me to add my own little flair to the code. I would say that the idea of 'meaningless words' is somewhat subjective and could differ based on the person, but I went to the internet for the best definition, as in the nltk library. \n",
    "\n",
    "My visualizations/plots were very straightforward, but I had the greatest amount of trouble in that section because I was initially confused by the prompt on how much I was plotting, and graphs can come out gross if you don't plot correctly. I will definitely work on teaching myself better plotting strategies to prevent these issues from happening next time. I had to rewrite certain aspects of those functions many times over.\n",
    " \n",
    "I rewrote over my original n-gram code for the 'hambot' assignment because I wanted to see if I could do it differently. Rewriting the code took some difficulty, but I feel I've updated it well for this current assignment. Generating the lyrics was definitely my favorite part of the assignment, so I'm glad I could create some unique code for that. \n",
    "\n",
    "For improvements, I could definitely optimize my code in certain aspects like the plotting areas or just cleaning text in general for next time. Maybe it was due to the immense number of data cells, but the run time for some functions does take quite a while. I also have some gripes with the way the prompt is written. There were certain sentences that were very vague, which made me have to consolidate with professors frequently on whether what I was doing was the correct implementation. \n",
    "\n",
    "Overall, I enjoyed this assignment, even when I became frustrated with the prompt and what I was supposed to do at times."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cc0846c953695e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additional comment about things I did within the assignment:\n",
    "\n",
    "For the 'artist_words' list I had, within each artist element, it was ordered as such:\n",
    "    Element 1: Artist name\n",
    "    Element 2: Dictionary with the keys as the artist's unique words and the values as their word counts\n",
    "    Element 3: The count of unique words in the artist's lyrics\n",
    "    Element 4: The artist's word richness score which I created"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab75afaebd80774"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6) Going above and beyond"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56bcd8d7e546da38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I am adding more, but I would say doing a word richness score should count for some part of this extra credit :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89d19f163c4726de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean text but don't split into words by stripping punctuation and converting to lowercase\n",
    "spotify_df['cleaned_text'] = spotify_df['text'].str.lower().str.replace('[^\\w\\s]', '')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3807f843c9efdc97"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I added a 'cleaned_text' column which just contains the cleaned text without splitting anything"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93535b882caf27a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding Artist's Emotion Distribution from Their Songs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd48e24937ce1350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    :param text: cleaned text\n",
    "    :return: the same text but with lemmatization and stopwords removed \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = word_tokenize(text)  \n",
    "    \n",
    "    # remove words with numbers\n",
    "    tokens = [token for token in tokens if token.isalpha()]  \n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words] \n",
    "    \n",
    "    return \" \".join(tokens)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bd2ea920d69803"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I'm going to attempt to extract certain emotions based upon analyzing song lyrics\n",
    "# to briefly explain, lemmatizing is the process of taking the variants of the same word and assigning them to a single word (i.e. 'changing', 'changed', and 'change' all become 'change')\n",
    "\n",
    "# preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize the text\n",
    "spotify_df['lemmatized_text'] = spotify_df['cleaned_text'].apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8560004390dbab8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create an emotion Lexicon \n",
    "emotion_lexicon = \\\n",
    "    {'happy': ['joy', 'happy', 'excited', 'cheerful', 'content', 'gleeful', 'wonderful'],\n",
    "    'sad': ['sad', 'unhappy', 'melancholy', 'gloomy', 'depressed', 'woeful'],\n",
    "    'angry': ['angry', 'rage', 'irritated', 'frustrated', 'fuming', 'livid'],\n",
    "    'love': ['affection', 'adoration', 'romance', 'caring', 'passion'],\n",
    "    'fear': ['fear', 'anxiety', 'dread', 'terror', 'panic', 'fright', 'horror'],\n",
    "    'envy': ['envy', 'jealousy', 'grudge', 'bitterness', 'spite', 'malice', 'pettiness'],\n",
    "    'boredom': ['boredom', 'tedium', 'monotony', 'dullness', 'lethargy', 'fatigue', 'staleness'],\n",
    "    'indifference': ['detachment', 'unconcern', 'nonchalance', 'disinterest', 'aloofness'],\n",
    "    'disgust': ['disgust', 'revulsion', 'repulsion', 'nausea', 'loathing', 'hatred', 'dislike' 'displeasure'],\n",
    "    'surprise': ['surprise', 'astonishment', 'amazement', 'shock', 'startle', 'awe', 'stun', 'confusion'],\n",
    "    'guilt': ['guilt', 'remorse', 'regret', 'shame', 'blame', 'sorrow', 'apology', 'guiltiness'],\n",
    "    'pride': ['pride', 'dignity', 'honor', 'vanity', 'arrogance', 'ego', 'superiority', 'swagger']}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460aeaecbbf64bc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate emotion scores\n",
    "def calculate_emotion_score(text):\n",
    "    \"\"\"\n",
    "    :param text: cleaned song text\n",
    "    :return: a dictionary of emotion scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # loop through text and attempt to find any words in the emotion lexicon\n",
    "    temp_emotion_scores = defaultdict(int)\n",
    "    for word in word_tokenize(text):\n",
    "        for temp_emotion, words in emotion_lexicon.items():\n",
    "            if word in words:\n",
    "                temp_emotion_scores[temp_emotion] += 1\n",
    "    \n",
    "    return dict(temp_emotion_scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad54febb9730d8d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get emotion scores for each score\n",
    "spotify_df['emotion_scores'] = spotify_df['lemmatized_text'].apply(calculate_emotion_score)\n",
    "\n",
    "# get emotion distribution for each artist\n",
    "artist_emotion_distribution = {}\n",
    "for artist, group in spotify_df.groupby('artist'):\n",
    "    emotion_scores = defaultdict(int)\n",
    "    \n",
    "    for emotion_dict in group['emotion_scores']:\n",
    "        for emotion, score in emotion_dict.items():\n",
    "            emotion_scores[emotion] += score\n",
    "    artist_emotion_distribution[artist] = dict(emotion_scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bd01dd278a52c11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_emotion_distribution(artist_name, artist_emotion_scores):\n",
    "    \"\"\"\n",
    "    :param artist_name: the artist's name\n",
    "    :param artist_emotion_scores: a specific artist\n",
    "    :return: null (plotting)\n",
    "    \"\"\"\n",
    "    \n",
    "    art_emotions = list(artist_emotion_scores.keys())\n",
    "    art_emotion_scores = list(artist_emotion_scores.values())\n",
    "    \n",
    "    # tried to make a cool visualization for the emotion score distribution; a pie chart\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(art_emotion_scores, labels=art_emotions,\n",
    "            autopct='%1.1f%%', startangle=140,\n",
    "            colors=plt.cm.tab10.colors)\n",
    "    \n",
    "    plt.axis('equal')\n",
    "    plt.title(f\"Emotion Distribution in {artist_name}'s Lyrics\", pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24886262ed2c7b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "# (i.e. plot_emotion_distribution('Kanye West', artist_emotion_distribution['Kanye West'])\n",
    "# plot_emotion_distribution('Kanye West', artist_emotion_distribution['Kanye West'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f421a554f02290b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
